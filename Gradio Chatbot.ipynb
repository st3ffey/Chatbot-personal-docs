{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = xxx\n",
    "\n",
    "# Define path to the cleaned text file\n",
    "path = 'doc.txt'\n",
    "\n",
    "# Load document and create vectorstore index once for faster querying\n",
    "loader = TextLoader(path)\n",
    "docs = loader.load()\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "\n",
    "# Implement conversation retrieval chain, a langchain pipeline for storing a conversation's history. \n",
    "# Specify the default 3.5 turbo model. Use GPT-4 for better quality results, but responses\n",
    "# Find the top 2 important bits of context.\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(model=\"gpt-3.5-turbo\"), retriever=index.vectorstore.as_retriever(search_kwargs={\"k\": 2}))\n",
    "\n",
    "# List to store the history of chats in the format [(question, answer), ...]\n",
    "chat_history = []\n",
    "\n",
    "# Convert the list chat_history to a list of tuples for easy manipulation. Gradio chat history expects list of tuples, rather than just list.\n",
    "chat_history_tuples = []\n",
    "for message in chat_history:\n",
    "    chat_history_tuples.append((message[0], message[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8619913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chat interface using Gradio\n",
    "with gr.Blocks() as demo:\n",
    "    # Display a title for the chat interface.\n",
    "    gr.Markdown('# Chat: Ask questions about xxx')\n",
    "    \n",
    "    # Create a chatbot component to display the chat history.\n",
    "    chatbot = gr.Chatbot()\n",
    "    \n",
    "    # Create a textbox for users to input their questions.\n",
    "    msg = gr.Textbox(\"Enter a question here!\")\n",
    "    \n",
    "    # Create a button for users to clear the chat history.\n",
    "    clear = gr.Button(\"Click here to clear chat history\")\n",
    "    \n",
    "    # Reset the chat history when starting a new session.\n",
    "    chat_history = []\n",
    "\n",
    "    # Primary function for chatbot interface\n",
    "    def user(query, chat_history):\n",
    "        \"\"\"\n",
    "        Process the user's query and return an answer.\n",
    "        \n",
    "        Parameters:\n",
    "        - query (str): The question input by the user.\n",
    "        - chat_history (list): List to maintain a running record of the chat.\n",
    "        \n",
    "        Returns:\n",
    "        - tuple: Empty string (placeholder for the UI) and updated chat history.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert the chat_history to a list of tuples for processing.\n",
    "        chat_history_tuples = []\n",
    "        for message in chat_history:\n",
    "            chat_history_tuples.append((message[0], message[1]))\n",
    "\n",
    "        # Call the `qa` function with the user's query and chat history to get an answer.\n",
    "        result = qa({\"question\": query, \"chat_history\": chat_history_tuples})\n",
    "\n",
    "        # Append the user's question and the received answer to the chat history.\n",
    "        chat_history.append((query, result[\"answer\"]))\n",
    "\n",
    "        return gr.update(value=\"\"), chat_history\n",
    "\n",
    "    # Trigger the `user` function when a question is submitted in the textbox.\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
    "    \n",
    "    # Clicking the clear button clears chat history.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "# Launch the Gradio chat interface with debugging enabled and shareability.\n",
    "demo.queue().launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
